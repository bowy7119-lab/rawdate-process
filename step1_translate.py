import json
import os
from concurrent.futures import ThreadPoolExecutor
from openai import OpenAI
from dotenv import load_dotenv
from tqdm import tqdm

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

INPUT_FILE = "egypt_processed_tagged.json"
OUTPUT_FILE = "egypt_data_enriched.json"

def translate_entry(entry):
    # ã™ã§ã«ç¿»è¨³æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
    if "english_translation" in entry and entry["english_translation"]:
        return entry
    
    # é•·ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯ã‚«ãƒƒãƒˆã—ã¦ç¿»è¨³ï¼ˆã‚³ã‚¹ãƒˆãƒ»ã‚¨ãƒ©ãƒ¼å¯¾ç­–ï¼‰
    text_snippet = entry['text'][:3000]
    
    try:
        # ç°¡æ˜“çš„ã‹ã¤é«˜é€Ÿãªç¿»è¨³
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Translate the Ancient Greek inscription to English. Output ONLY the translation."},
                {"role": "user", "content": text_snippet}
            ],
            temperature=0
        )
        entry["english_translation"] = response.choices[0].message.content
    except Exception:
        entry["english_translation"] = ""
    
    return entry

def main():
    if not os.path.exists(INPUT_FILE):
        print(f"ã‚¨ãƒ©ãƒ¼: {INPUT_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    print(f"ğŸš€ {len(data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã®è‹±è¨³å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
    
    # 10ä¸¦åˆ—ã§é«˜é€Ÿå‡¦ç†
    with ThreadPoolExecutor(max_workers=10) as executor:
        results = list(tqdm(executor.map(translate_entry, data), total=len(data)))

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=4)
    
    print(f"âœ… è‹±è¨³å®Œäº†ï¼ '{OUTPUT_FILE}' ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()