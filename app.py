import streamlit as st
import json
import os
import pandas as pd
import plotly.express as px
import chromadb
from openai import OpenAI
from dotenv import load_dotenv
from collections import defaultdict
import re

# --- åŸºæœ¬è¨­å®š ---
load_dotenv()
st.set_page_config(page_title="Egyptian Greek Inscription Analyzer", layout="wide")
CHROMA_PATH = "./chroma_db_store"
DATA_FILE = "egypt_data_enriched.json"
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥) ---
@st.cache_resource
def get_chroma_db():
    if not os.path.exists(CHROMA_PATH): return None
    return chromadb.PersistentClient(path=CHROMA_PATH).get_collection("inscriptions")

@st.cache_data
def load_json_data():
    if not os.path.exists(DATA_FILE): return []
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

# --- â‘  UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: å‡ºå…¸ãƒªã‚¹ãƒˆè¡¨ç¤º ---
def render_citation_list(inscriptions, max_items=20, title_prefix="ãƒ’ãƒƒãƒˆã—ãŸç¢‘æ–‡"):
    """
    IDã¨å¹´ä»£ã‚’ãƒªã‚¹ãƒˆè¡¨ç¤ºã—ã€ã‚¯ãƒªãƒƒã‚¯ã§åŸæ–‡ï¼ˆæŠ˜ã‚Šè¿”ã—ï¼‰ã¨è‹±è¨³ã‚’è¡¨ç¤ºã™ã‚‹å…±é€šé–¢æ•°
    """
    st.markdown(f"### ğŸ“œ {title_prefix} (Top {min(len(inscriptions), max_items)})")
    
    for item in inscriptions[:max_items]:
        # ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†
        label = f"**ID: {item['id']}** | Date: {item.get('date_min')} ~ {item.get('date_max')} | {item.get('region_sub', 'Unknown')}"
        
        with st.expander(label):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Original Greek:**")
                # ã‚®ãƒªã‚·ã‚¢èªã‚’æŠ˜ã‚Šè¿”ã—ã¦è¡¨ç¤ºã™ã‚‹ãŸã‚ã«markdownã‚’ä½¿ç”¨
                st.markdown(f"<div style='word-wrap: break-word;'>{item['text']}</div>", unsafe_allow_html=True)
            with col2:
                st.markdown("**English Translation:**")
                st.write(item.get('english_translation', '(No translation)'))

# --- â‘¡ ãƒ­ã‚¸ãƒƒã‚¯: AIã«ã‚ˆã‚‹ã‚¯ã‚¨ãƒªæ‹¡å¼µ (ä¿®æ­£ç‰ˆ) ---
def get_smart_search_terms(user_query):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‹ã‚‰ã€æ¤œç´¢ã«å¿…è¦ãªã€Œè‹±èªæ¦‚å¿µã€ã¨ã€Œã‚®ãƒªã‚·ã‚¢èªã®å…¨å¤‰åŒ–å½¢ã€ã‚’ç”Ÿæˆã™ã‚‹
    """
    system_prompt = """
    You are an expert Ancient Greek Historian.
    Analyze the user's query and return a JSON object with two lists.
    
    IMPORTANT: You must generate ACTUAL GREEK WORDS, not placeholders.
    
    Example Input: "ÎºÎ±Î¹ÏƒÎ±Ï"
    Example Output:
    {
      "greek_forms": ["ÎºÎ±Î¹ÏƒÎ±Ï", "ÎºÎ±Î¹ÏƒÎ±ÏÎ¿Ï‚", "ÎºÎ±Î¹ÏƒÎ±ÏÎ¹", "ÎºÎ±Î¹ÏƒÎ±ÏÎ±", "ÎºÎ±Î¹ÏƒÎ±ÏÏ‰Î½", "ÎºÎ±Î¹ÏƒÎ±ÏÏƒÎ¹"],
      "english_keywords": ["Caesar", "Emperor", "Imperial"]
    }

    Task:
    1. "greek_forms": List the lemma AND ALL inflected forms (nom/gen/dat/acc, sg/pl).
    2. "english_keywords": English translations and related concepts.
    """
    
    try:
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query}
            ],
            response_format={"type": "json_object"},
            temperature=0.1 # å‰µé€ æ€§ã‚’ä¸‹ã’ã¦ç¢ºå®Ÿã«ç­”ãˆã•ã›ã‚‹
        )
        result = json.loads(res.choices[0].message.content)
        
        # ã€ä¿é™ºã€‘ã‚‚ã—AIãŒå…¥åŠ›ã—ãŸå˜èªãã®ã‚‚ã®ã‚’å¿˜ã‚Œã¦ã„ãŸã‚‰è¿½åŠ ã™ã‚‹
        if user_query not in result.get('greek_forms', []):
            result.setdefault('greek_forms', []).append(user_query)
            
        return result
    except:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…¥åŠ›ãã®ã‚‚ã®ã‚’è¿”ã™
        return {"greek_forms": [user_query], "english_keywords": [user_query]}

# --- â‘¢ ãƒ­ã‚¸ãƒƒã‚¯: è©³ç´°æ¤œç´¢ & é›†è¨ˆ ---
def analyze_data(data, search_terms):
    """
    å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èµ°æŸ»ã—ã€ä»¥ä¸‹ã®3ã¤ã‚’è¨ˆç®—ã™ã‚‹
    1. å¹´ä»£æ¨ç§» (Line Chartç”¨)
    2. èªå½¢ã”ã¨ã®ãƒ’ãƒƒãƒˆæ•° (Pie Chartç”¨)
    3. ãƒ’ãƒƒãƒˆã—ãŸç¢‘æ–‡ãƒªã‚¹ãƒˆ
    """
    years_map = defaultdict(float)
    form_counts = defaultdict(int)
    matched_items = []
    
    # æ¤œç´¢èªã®æº–å‚™
    greek_targets = [t for t in search_terms.get('greek_forms', []) if t]
    english_targets = [t.lower() for t in search_terms.get('english_keywords', []) if t]
    
    for d in data:
        is_hit = False
        text_greek = d['text'] # Case sensitive for Greek usually, but let's keep original
        text_eng = d.get('english_translation', '').lower()
        
        # A. ã‚®ãƒªã‚·ã‚¢èªå½¢ã®ãƒãƒƒãƒãƒ³ã‚°ï¼ˆå††ã‚°ãƒ©ãƒ•ç”¨ï¼‰
        # æ­£è¦è¡¨ç¾ã‚’ä½¿ã‚ãšã€å˜ç´”ãªåŒ…å«ç¢ºèªã‚’è¡Œã†ï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚ï¼‰
        for g_form in greek_targets:
            if g_form in text_greek:
                form_counts[g_form] += 1
                is_hit = True
        
        # B. è‹±èªæ¦‚å¿µã®ãƒãƒƒãƒãƒ³ã‚°ï¼ˆãƒ’ãƒƒãƒˆæ¼ã‚Œé˜²æ­¢ç”¨ï¼‰
        if not is_hit:
            for e_word in english_targets:
                if e_word in text_eng:
                    is_hit = True
                    break
        
        # ãƒ’ãƒƒãƒˆã—ãŸå ´åˆã®å¹´ä»£é›†è¨ˆ
        if is_hit:
            matched_items.append(d)
            s, e = int(d.get('date_min', 0)), int(d.get('date_max', 0))
            if s == 0 and e == 0: continue
            
            duration = e - s + 1
            weight = 1.0 / duration if duration > 0 else 1.0
            for y in range(s, e + 1):
                years_map[y] += weight
                
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å¤‰æ›
    df_trend = pd.DataFrame(list(years_map.items()), columns=["Year", "Frequency"]).sort_values("Year")
    df_pie = pd.DataFrame(list(form_counts.items()), columns=["Form", "Count"]).sort_values("Count", ascending=False)
    
    return df_trend, df_pie, matched_items

# --- ãƒ¡ã‚¤ãƒ³ UI ---
st.title("ğŸ›ï¸ Egyptian Greek Inscription Analyzer")
st.caption("Morphological Analysis & AI Historian")

collection = get_chroma_db()
full_data = load_json_data()

if collection is None:
    st.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Step 2 ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    st.stop()

tab_trend, tab_chat = st.tabs(["ğŸ“Š å¹´ä»£æ¨ç§»ãƒ»èªå½¢åˆ†æ", "ğŸ¤– æ­´å²å®¶ãƒãƒ£ãƒƒãƒˆ"])

# === Tab 1: å¹´ä»£æ¨ç§» & å††ã‚°ãƒ©ãƒ• ===
with tab_trend:
    st.subheader("æ¦‚å¿µãƒ»èªå½¢å¤‰åŒ–ã®åˆ†æ")
    query = st.text_input("æ¤œç´¢èªï¼ˆä¾‹: ÎºÎ±Î¹ÏƒÎ±Ï, ãƒ—ãƒˆãƒ¬ãƒã‚¤ã‚ªã‚¹1ä¸–ï¼‰", "ÎºÎ±Î¹ÏƒÎ±Ï")
    
    if st.button("åˆ†æå®Ÿè¡Œ"):
        with st.spinner("AIãŒèªå½¢å¤‰åŒ–ã‚’å±•é–‹ã—ã€å…¨ç¢‘æ–‡ã‚’è§£æä¸­..."):
            # 1. AIå±•é–‹
            expanded = get_smart_search_terms(query)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            with st.expander("ğŸ” AIãŒç”Ÿæˆã—ãŸæ¤œç´¢ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ (ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç¢ºèª)"):
                st.write(f"**Greek Forms:** {', '.join(expanded.get('greek_forms', []))}")
                st.write(f"**English Keywords:** {', '.join(expanded.get('english_keywords', []))}")
            
            # 2. é›†è¨ˆå®Ÿè¡Œ
            df_trend, df_pie, hits = analyze_data(full_data, expanded)
            
            if not df_trend.empty:
                # 3. ã‚°ãƒ©ãƒ•è¡¨ç¤º
                col_graph1, col_graph2 = st.columns([2, 1])
                
                with col_graph1:
                    st.markdown("#### ğŸ“ˆ å¹´ä»£æ¨ç§» (Frequency)")
                    fig_line = px.line(df_trend, x="Year", y="Frequency", title=f"Trend: {query}")
                    st.plotly_chart(fig_line, use_container_width=True)
                
                with col_graph2:
                    st.markdown("#### ğŸ° èªå½¢å‡ºç¾æ¯”ç‡")
                    if not df_pie.empty:
                        fig_pie = px.pie(df_pie, values="Count", names="Form", title="Greek Forms Distribution")
                        st.plotly_chart(fig_pie, use_container_width=True)
                    else:
                        st.info("ã‚®ãƒªã‚·ã‚¢èªå½¢ã®ç›´æ¥ä¸€è‡´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆè‹±èªæ¦‚å¿µã®ã¿ãƒ’ãƒƒãƒˆï¼‰")

                # 4. å…±é€šãƒªã‚¹ãƒˆå½¢å¼ã§å‡ºå…¸è¡¨ç¤º
                render_citation_list(hits, title_prefix="åˆ†æå¯¾è±¡ã¨ãªã£ãŸç¢‘æ–‡")
                
            else:
                st.warning("è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# === Tab 2: AIãƒãƒ£ãƒƒãƒˆ ===
with tab_chat:
    st.subheader("Evidence-Based Chat")
    
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
        
    for msg in st.session_state.chat_history:
        st.chat_message(msg["role"]).write(msg["content"])
        
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ› (ä¾‹: ãƒ—ãƒˆãƒ¬ãƒã‚¤ã‚ªã‚¹1ä¸–ã®çµ±æ²»ã«ã¤ã„ã¦)"):
        st.chat_message("user").write(prompt)
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        with st.spinner("AIãŒé–¢é€£èªã‚’æ¨è«–ã—ã€æ–‡çŒ®ã‚’æ¤œç´¢ä¸­..."):
            # 1. AIæ¨è«– (Step 1)
            plan = get_smart_search_terms(prompt)
            search_text = " ".join(plan.get('english_keywords', []) + plan.get('greek_forms', []))
            
            # 2. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ (Step 2)
            # AIãŒè€ƒãˆãŸã€Œã‚½ãƒ†ãƒ«ã€ã€Œãƒ™ãƒ¬ãƒ‹ã‚±ã€ãªã©ã®é–¢é€£èªã‚‚å«ã‚ã¦æ¤œç´¢
            q_vec = client.embeddings.create(input=[search_text], model="text-embedding-3-small").data[0].embedding
            results = collection.query(query_embeddings=[q_vec], n_results=20)
            
            # 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
            context_str = ""
            ref_data = []
            id_map = {str(d['id']): d for d in full_data}
            
            for doc, meta in zip(results['documents'][0], results['metadatas'][0]):
                context_str += f"[ID: {meta['id']}] {doc[:600]}...\n\n"
                # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦å‚ç…§ãƒªã‚¹ãƒˆç”¨ã«ã™ã‚‹
                original = id_map.get(str(meta['id']))
                if original:
                    ref_data.append(original)
            
            # 4. å›ç­”ç”Ÿæˆ (Step 3)
            system_msg = """
            ã‚ãªãŸã¯å¤ä»£ã‚¨ã‚¸ãƒ—ãƒˆãƒ»ã‚®ãƒªã‚·ã‚¢ç¢‘æ–‡ã®å°‚é–€å®¶ã§ã™ã€‚
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€æä¾›ã•ã‚ŒãŸã€Contextã€‘ã‚’è¨¼æ‹ ã¨ã—ã¦ç”¨ã„ãªãŒã‚‰ã€
            æ—¥æœ¬èªã§ã€å­¦è¡“çš„ã‹ã¤è«–ç†çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
            å›ç­”ã®ä¸­ã§ä¸»å¼µã‚’è¡Œã†éš›ã¯ã€å¿…ãš [ID: xxxxx] ã®å½¢å¼ã§å‡ºå…¸ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
            """
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": f"Context:\n{context_str}\n\nQuestion: {prompt}"}
                ]
            )
            ans = response.choices[0].message.content
            
        st.chat_message("assistant").write(ans)
        st.session_state.chat_history.append({"role": "assistant", "content": ans})
        
        # 5. å…±é€šãƒªã‚¹ãƒˆå½¢å¼ã§ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹è¡¨ç¤º
        with st.expander("ğŸ“š AIã®æ¤œç´¢æˆ¦ç•¥ & å‚ç…§ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹"):
            st.info(f"**AIãŒæ¤œç´¢ã—ãŸé–¢é€£èª:** {', '.join(plan.get('english_keywords', [])[:10])} ...")
            render_citation_list(ref_data, title_prefix="å›ç­”ã«ä½¿ç”¨ã—ãŸç¢‘æ–‡")