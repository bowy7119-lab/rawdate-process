import streamlit as st
import json
import os
import pandas as pd
import plotly.express as px
import chromadb
from openai import OpenAI
from dotenv import load_dotenv
from collections import defaultdict
import unicodedata
import re

# --- åŸºæœ¬è¨­å®š ---
load_dotenv()
st.set_page_config(page_title="Egyptian Greek Inscription Analyzer", layout="wide")

# ãƒ‘ã‚¹è¨­å®š
CHROMA_PATH = "./chroma_db_store"
DATA_FILE = "egypt_data_final.json" # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆStep 1.5ã®ã‚‚ã®ã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€lemmasãŒãªãã¦ã‚‚å‹•ãã‚ˆã†ã«è¨­è¨ˆï¼‰

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.title("âš™ï¸ Settings")
    st.subheader("AI Model")
    chat_model = st.selectbox(
        "Select Model",
        ["gpt-4o", "gpt-4o-mini"],
        index=0,
        help="gpt-4o: é«˜ç²¾åº¦\ngpt-4o-mini: é«˜é€Ÿ"
    )
    st.divider()
    st.subheader("Chat History")
    if st.button("ğŸ—‘ï¸ Clear History"):
        st.session_state.history = []
        st.rerun()

# --- ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ ---
@st.cache_resource
def get_chroma_db():
    if not os.path.exists(CHROMA_PATH): return None
    return chromadb.PersistentClient(path=CHROMA_PATH).get_collection("inscriptions")

@st.cache_data
def load_json_data():
    if not os.path.exists(DATA_FILE): return []
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

# --- ğŸ› ï¸ ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: å¼·åŠ›ãªæ­£è¦åŒ– ---
def normalize_text(text):
    """
    ç¢‘æ–‡æ¤œç´¢ç”¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ã™ã‚‹ã€‚
    1. å°æ–‡å­—åŒ–
    2. ã‚¢ã‚¯ã‚»ãƒ³ãƒˆãƒ»æ°—æ¯è¨˜å·ã®é™¤å» (NFDåˆ†è§£)
    3. ç¢‘æ–‡è¨˜å· ([], (), <>, {}, .) ã®é™¤å»
    4. ç•°ä½“å­— (Ï‚ -> Ïƒ) ã®çµ±ä¸€
    """
    if not text: return ""
    text = str(text).lower()
    
    # Unicodeæ­£è¦åŒ– (ã‚¢ã‚¯ã‚»ãƒ³ãƒˆåˆ†é›¢ã—ã¦å‰Šé™¤)
    text = ''.join(c for c in unicodedata.normalize('NFD', text)
                   if unicodedata.category(c) != 'Mn')
    
    # è¨˜å·å‰Šé™¤: [ ] ( ) < > { } .
    # ã“ã‚Œã«ã‚ˆã‚Š "[Îº]Î±Î¹ÏƒÎ±Ï" -> "ÎºÎ±Î¹ÏƒÎ±Ï" ã«ãªã‚‹
    text = re.sub(r'[\[\]\(\)<>\{\}\.]', '', text)
    
    # ãƒ•ã‚¡ã‚¤ãƒŠãƒ«ã‚·ã‚°ãƒç­‰ã®çµ±ä¸€
    text = text.replace('Ï‚', 'Ïƒ')
    
    # ä½™åˆ†ãªç©ºç™½å‰Šé™¤
    text = text.strip()
    
    return text

# --- ğŸ§  AIãƒ­ã‚¸ãƒƒã‚¯: æ¤œç´¢èªã®æ‹¡å¼µ ---
def get_expanded_search_terms(query):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‹ã‚‰ã€æ¤œç´¢ã™ã¹ãã€Œã‚®ãƒªã‚·ã‚¢èªã®å…¨å¤‰åŒ–å½¢ã€ã¨ã€Œè‹±èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã‚’AIã«ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã•ã›ã‚‹
    """
    system_prompt = """
    You are an expert Ancient Greek Philologist.
    Analyze the user's query and return a JSON object with:
    1. "greek_forms": A list of the lemma AND ALL inflected forms (cases, numbers).
       Example: Input "ÎºÎ±Î¹ÏƒÎ±Ï" -> Output ["ÎºÎ±Î¹ÏƒÎ±Ï", "ÎºÎ±Î¹ÏƒÎ±ÏÎ¿Ï‚", "ÎºÎ±Î¹ÏƒÎ±ÏÎ¹", "ÎºÎ±Î¹ÏƒÎ±ÏÎ±", "ÎºÎ±Î¹ÏƒÎ±ÏÏ‰Î½", "ÎºÎ±Î¹ÏƒÎ±ÏÏƒÎ¹"]
       IMPORTANT: Normalize them (no accents).
    2. "english_keywords": English translations.
    """
    
    try:
        res = client.chat.completions.create(
            model="gpt-4o-mini", # é«˜é€Ÿãªãƒ¢ãƒ‡ãƒ«ã§ååˆ†
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            response_format={"type": "json_object"},
            temperature=0.0
        )
        return json.loads(res.choices[0].message.content)
    except:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…¥åŠ›ãã®ã¾ã¾è¿”ã™
        return {"greek_forms": [query], "english_keywords": [query]}

# --- ğŸ“Š ãƒ­ã‚¸ãƒƒã‚¯: ãƒ‡ãƒ¼ã‚¿åˆ†æ ---
def analyze_data_robust(data, query):
    years_map = defaultdict(float)
    form_counts = defaultdict(int)
    matched_items = []
    
    # 1. AIã‚’ä½¿ã£ã¦æ¤œç´¢èªã‚’æ‹¡å¼µ (ä¾‹: "ÎºÎ±Î¹ÏƒÎ±Ï" -> ["ÎºÎ±Î¹ÏƒÎ±Ï", "ÎºÎ±Î¹ÏƒÎ±ÏÎ¿Ï‚", ...])
    expanded = get_expanded_search_terms(query)
    
    # 2. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’æ­£è¦åŒ–ã‚»ãƒƒãƒˆã«å¤‰æ›
    # AIãŒå‡ºã—ãŸå¤‰åŒ–å½¢ã‚’ã•ã‚‰ã«æ­£è¦åŒ–ã—ã¦ã‚»ãƒƒãƒˆã«ã™ã‚‹
    target_greek = set([normalize_text(w) for w in expanded.get('greek_forms', [])])
    target_eng = set([w.lower() for w in expanded.get('english_keywords', [])])
    
    # å¿µã®ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãã®ã‚‚ã®ã‚‚ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«è¿½åŠ 
    target_greek.add(normalize_text(query))

    for d in data:
        is_hit = False
        
        # --- A. ã‚®ãƒªã‚·ã‚¢èªæ¤œç´¢ (æ­£è¦åŒ–ãƒãƒƒãƒãƒ³ã‚°) ---
        text_raw = d.get('text', '')
        # åŸæ–‡ã‚’å˜èªåˆ†å‰²
        # è¨˜å·è¾¼ã¿ã§ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ã®ã§ã€ã¾ãšã¯split
        words_raw = re.split(r'\s+', text_raw)
        
        for w_raw in words_raw:
            # å˜èªã”ã¨ã«æ­£è¦åŒ– (ä¾‹: "[Îº]Î±Î¹ÏƒÎ±Ï" -> "ÎºÎ±Î¹ÏƒÎ±Ï")
            w_norm = normalize_text(w_raw)
            
            # æ­£è¦åŒ–å¾Œã®å˜èªãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹ã‹ï¼Ÿ
            if w_norm in target_greek:
                is_hit = True
                if len(w_norm) > 1: # 1æ–‡å­—ã®ã‚´ãƒŸã‚’é™¤å»
                    # å††ã‚°ãƒ©ãƒ•ç”¨: æ­£è¦åŒ–å¾Œã®å½¢ã§ã‚«ã‚¦ãƒ³ãƒˆï¼ˆè¡¨è¨˜ã‚†ã‚Œã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ï¼‰
                    form_counts[w_norm] += 1
        
        # --- B. è‹±èªæ¤œç´¢ (æ•‘æ¸ˆæªç½®) ---
        if not is_hit:
            content_eng = str(d.get('english_translation', '')).lower()
            # è‹±èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã©ã‚Œã‹ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
            for eng_key in target_eng:
                if eng_key in content_eng:
                    is_hit = True
                    break

        # --- é›†è¨ˆ ---
        if is_hit:
            s, e = int(d.get('date_min', 0)), int(d.get('date_max', 0))
            # æ˜ã‚‰ã‹ã«ãŠã‹ã—ã„å¹´ä»£(0-0ãªã©)ã‚’é™¤å¤–ã™ã‚‹ãŒã€åºƒç¯„å›²ã®ã‚‚ã®ã¯è¨±å®¹
            if s == 0 and e == 0: 
                pass 
            else:
                duration = e - s + 1
                # æœŸé–“ãŒé•·ã™ãã‚‹ã‚‚ã®(500å¹´ä»¥ä¸Šãªã©)ã¯ãƒã‚¤ã‚ºã«ãªã‚‹ã®ã§é‡ã¿ã‚’ä¸‹ã’ã‚‹ã€ã‚ã‚‹ã„ã¯é™¤å¤–ã‚‚æ¤œè¨
                # ã“ã“ã§ã¯å˜ç´”ã«ä¸€æ§˜åˆ†å¸ƒ
                weight = 1.0 / duration if duration > 0 else 1.0
                for y in range(s, e + 1):
                    years_map[y] += weight
                matched_items.append(d)
            
    df_trend = pd.DataFrame(list(years_map.items()), columns=["Year", "Frequency"]).sort_values("Year")
    # å††ã‚°ãƒ©ãƒ•: ã‚«ã‚¦ãƒ³ãƒˆãŒå¤šã„é †
    df_pie = pd.DataFrame(list(form_counts.items()), columns=["Form", "Count"]).sort_values("Count", ascending=False)
    
    return df_trend, df_pie, matched_items, list(target_greek)

# --- UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: å‡ºå…¸ãƒªã‚¹ãƒˆ ---
def render_citation_list(inscriptions, max_items=20, title_prefix="ãƒ’ãƒƒãƒˆã—ãŸç¢‘æ–‡"):
    st.markdown(f"### ğŸ“œ {title_prefix} (Top {min(len(inscriptions), max_items)})")
    
    seen_ids = set()
    unique_items = []
    for item in inscriptions:
        if item['id'] not in seen_ids:
            unique_items.append(item)
            seen_ids.add(item['id'])
            
    for item in unique_items[:max_items]:
        label = f"**ID: {item['id']}** | {item.get('date_min')}~{item.get('date_max')} | {item.get('region_sub', 'Unknown')}"
        with st.expander(label):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**Original Greek:**")
                st.markdown(f"<div style='word-wrap: break-word; font-family: sans-serif; color: #aaa;'>{item['text']}</div>", unsafe_allow_html=True)
            with col2:
                st.markdown("**English Translation:**")
                st.write(item.get('english_translation', '(No translation)'))

# --- ãƒ¡ã‚¤ãƒ³ UI ---
st.title("ğŸ›ï¸ Egyptian Greek Inscription Analyzer")
st.caption(f"Powered by AI & Robust Normalization | Model: {chat_model}")

collection = get_chroma_db()
full_data = load_json_data()

if collection is None or not full_data:
    st.error("ãƒ‡ãƒ¼ã‚¿æº–å‚™ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“ã€‚Step 1 (ã¾ãŸã¯1.5), Step 2 ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    st.stop()

tab_trend, tab_chat = st.tabs(["ğŸ“Š å³å¯†èªå½¢åˆ†æ", "ğŸ¤– æ­´å²å®¶ãƒãƒ£ãƒƒãƒˆ"])

# === Tab 1 ===
with tab_trend:
    st.subheader("AIæ¨è«–ã¨æ­£è¦åŒ–ã«ã‚ˆã‚‹å¹´ä»£æ¨ç§»")
    query = st.text_input("æ¤œç´¢èªï¼ˆä¾‹: ÎºÎ±Î¹ÏƒÎ±Ï, ptolemyï¼‰", "ÎºÎ±Î¹ÏƒÎ±Ï")
    
    if st.button("åˆ†æå®Ÿè¡Œ"):
        if not query:
            st.warning("æ¤œç´¢èªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            with st.spinner("AIãŒå¤‰åŒ–å½¢ã‚’å±•é–‹ã—ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ç…§åˆä¸­..."):
                df_trend, df_pie, hits, search_stems = analyze_data_robust(full_data, query)
                
                # æ¤œç´¢ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®è¡¨ç¤ºï¼ˆæœ€åˆã®10å€‹ãã‚‰ã„ï¼‰
                st.info(f"ğŸ” æ¤œç´¢ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ(æ­£è¦åŒ–æ¸ˆ): {', '.join(list(search_stems)[:15])} ...")
                
                if not df_trend.empty:
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        st.markdown(f"#### ğŸ“ˆ å¹´ä»£æ¨ç§» (Hit: {len(hits)})")
                        fig_line = px.line(df_trend, x="Year", y="Frequency", title=f"Trend: {query}")
                        st.plotly_chart(fig_line, use_container_width=True)
                    with col2:
                        st.markdown("#### ğŸ° èªå½¢å‡ºç¾æ¯”ç‡ (æ­£è¦åŒ–å¾Œ)")
                        if not df_pie.empty:
                            fig_pie = px.pie(df_pie, values="Count", names="Form", title=f"Variations of '{query}'")
                            st.plotly_chart(fig_pie, use_container_width=True)
                        else:
                            st.caption("â€» ã‚®ãƒªã‚·ã‚¢èªå½¢ã®ç›´æ¥ä¸€è‡´ãªã—ï¼ˆè‹±èªæ¦‚å¿µãƒ’ãƒƒãƒˆã®ã¿ï¼‰")
                            
                    render_citation_list(hits, title_prefix="æ¤œç´¢ãƒ’ãƒƒãƒˆ")
                else:
                    st.warning("è©²å½“ãƒ‡ãƒ¼ã‚¿ãªã—")

# === Tab 2 ===
with tab_chat:
    st.subheader("Evidence-Based Chat")
    
    if "history" not in st.session_state: st.session_state.history = []
    
    for m in st.session_state.history:
        st.chat_message(m["role"]).write(m["content"])
    
    if p := st.chat_input("è³ªå•ã‚’å…¥åŠ›..."):
        st.session_state.history.append({"role": "user", "content": p})
        st.chat_message("user").write(p)
        
        with st.spinner(f"{chat_model} ãŒæ¤œç´¢ä¸­..."):
            # 1. æ¤œç´¢ç”¨ã‚¯ã‚¨ãƒªã®ç”Ÿæˆ (AIã§æ‹¡å¼µ)
            expanded = get_expanded_search_terms(p)
            search_text = " ".join(expanded.get('english_keywords', []) + expanded.get('greek_forms', []))
            
            # 2. ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
            q_vec = client.embeddings.create(input=[search_text], model="text-embedding-3-small").data[0].embedding
            results = collection.query(query_embeddings=[q_vec], n_results=20)
            
            # 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
            context_str = ""
            ref_data = []
            seen_refs = set()
            id_map = {str(d['id']): d for d in full_data}
            
            for doc, meta in zip(results['documents'][0], results['metadatas'][0]):
                mid = str(meta['id'])
                if mid not in seen_refs:
                    context_str += f"[ID: {mid}] {doc[:600]}...\n\n"
                    orig = id_map.get(mid)
                    if orig: ref_data.append(orig)
                    seen_refs.add(mid)
            
            # 4. å›ç­”ç”Ÿæˆ
            sys_msg = """
            ã‚ãªãŸã¯å¤ä»£ã‚¨ã‚¸ãƒ—ãƒˆãƒ»ã‚®ãƒªã‚·ã‚¢ç¢‘æ–‡ã®å°‚é–€å®¶ã§ã™ã€‚
            è¨¼æ‹ ã€Contextã€‘ã«åŸºã¥ãã€å¿…ãš [ID: xxxxx] ã‚’å¼•ç”¨ã—ã¦æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
            ç¢‘æ–‡ç‰¹æœ‰ã®è¨˜å·ï¼ˆ[ ] ã‚„ ( )ï¼‰ã¯ã€èª­ã¿ã‚„ã™ã„ã‚ˆã†ã«è£œå®Œã—ã¦è§£é‡ˆã—ã¦ãã ã•ã„ã€‚
            """
            
            ans = client.chat.completions.create(
                model=chat_model,
                messages=[
                    {"role": "system", "content": sys_msg},
                    {"role": "user", "content": f"Context:\n{context_str}\n\nQuestion: {p}"}
                ]
            ).choices[0].message.content
            
        st.chat_message("assistant").write(ans)
        st.session_state.history.append({"role": "assistant", "content": ans})
        
        with st.expander("ğŸ“š å‚ç…§ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹"):
            render_citation_list(ref_data, title_prefix="å‚ç…§ãƒ‡ãƒ¼ã‚¿")